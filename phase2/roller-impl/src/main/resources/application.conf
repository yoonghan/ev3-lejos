play.application.loader = com.walcron.lagom.lego.impl.RollerLoader
play.http.secret.key = somenotverysecretivesecret

roller-lagom.cassandra.keyspace = rollerlagom

cassandra-journal.keyspace = ${roller-lagom.cassandra.keyspace}
cassandra-snapshot-store.keyspace = ${roller-lagom.cassandra.keyspace}
lagom.persistence.read-side.cassandra.keyspace = ${roller-lagom.cassandra.keyspace}

# The properties below override Lagom default configuration with the recommended values for new projects.
#
# Lagom has not yet made these settings the defaults for backward-compatibility reasons.

# Prefer 'ddata' over 'persistence' to share cluster sharding state for new projects.
# See https://doc.akka.io/docs/akka/current/cluster-sharding.html#distributed-data-vs-persistence-mode
akka.cluster.sharding.state-store-mode = ddata

# Enable the serializer provided in Akka 2.5.8+ for akka.Done and other internal
# messages to avoid the use of Java serialization.
akka.actor.serialization-bindings {
  "akka.Done"                 = akka-misc
  "akka.actor.Address"        = akka-misc
  "akka.remote.UniqueAddress" = akka-misc
}

kamon.util.filters {
  "akka.tracked-actor" {
    includes = [ "**" ]
  }

  "akka.tracked-dispatcher" {
    includes = [ "**" ]
  }

  "akka.traced-actor" {
    includes = [ "**" ]
  }

  "test" {
    includes = [ "**" ]
  }
}


cassandra.default {
  ## list the contact points  here
  contact-points = [${DB_HOST_IP}]
  ## override Lagomâ€™s ServiceLocator-based ConfigSessionProvider
  session-provider = akka.persistence.cassandra.ConfigSessionProvider
}

cassandra-journal {
  contact-points = ${cassandra.default.contact-points}
  session-provider = ${cassandra.default.session-provider}
}

cassandra-snapshot-store {
  contact-points = ${cassandra.default.contact-points}
  session-provider = ${cassandra.default.session-provider}
}

lagom.persistence.read-side.cassandra {
  contact-points = ${cassandra.default.contact-points}
  session-provider = ${cassandra.default.session-provider}
}

# There must be 2 or more seeds defined. First seed must be same for all server startup to avoid new cluster formed.
akka.cluster.seed-nodes = [
  "akka.tcp://"${APPLICATION_NAME}"@"${FIRST_HOST_IP}":"${FIRST_HOST_PORT},
  "akka.tcp://"${APPLICATION_NAME}"@"${SECOND_HOST_IP}":"${SECOND_HOST_PORT}
]

akka {
  remote {
    netty.tcp {
      hostname = ${HOST_IP}      # external (logical) hostname
      port = ${HOST_PORT}                   # external (logical) port

      bind-hostname = ${BIND_IP} # internal (bind) hostname
      bind-port = ${BIND_PORT}              # internal (bind) port
    }
 }
}

# Close this if seeds nodes are defined.
#lagom.defaults.cluster.join-self = on
lagom.persistence.ask-timeout=30s

lagom.broker.defaults.kafka {
  # See {lagom.broker.kafka.brokers} for documentation about this
  # configuration key.
  brokers = ${?KAFKA_HOST_IP_AND_PORT}
}

#//#kafka-broker
lagom.broker.kafka {
  service-name = ""

  brokers = ${lagom.broker.defaults.kafka.brokers}

  client {
    default {
      failure-exponential-backoff {
        min = 3s
        max = 30s
        random-factor = 0.2
      }
    }

    producer = ${lagom.broker.kafka.client.default}
    producer.role = ""

    consumer {
      failure-exponential-backoff = ${lagom.broker.kafka.client.default.failure-exponential-backoff}
      offset-buffer = 100
      batching-size = 20
      batching-interval = 5 seconds
    }
  }
}